---
aliases:
  - שיטות איטראטיביות
  - שיטת יעקובי
  - שיטת גאוס-זיידל
  - שיטת SOR
  - איטרציה בנקודה קבועה
  - התכנסות שיטות איטרטיביות
  - מטריצת האיטרציה
---

# מבוא
ישנם מצבים בהם נעדיף לתקוף את המערכות הלינאריות מזווית אחרת, ולא ב[[NUM1_002 שיטות ישירות לפתרון מערכות לינאריות|ישירות]] כמו שעשינו בשיטות הקודמות.

מספר חסרונות של השיטות הישירות:

- לפעמים לא נרצה לפתור את המערכת בדיוק רב. לרוב, מספיק לפתור את המערכת עד לרמה נמוכה של דיוק. שיטות ישירות לא יכולות לבצע זאת, כי בהגדרתם, כדי להגיע לתשובה חייבים לסיים את כל האלגוריתם.
- לפעמים כבר אנחנו יודעים בערך איך תראה התשובה. למשל, בבעיות שתלויות בזמן, אנחנו יכולים לפתור את הבעיה עבור זמן מסוים, ואז לפתור אותה עבור זמן טיפה יותר מאוחר. לרוב, הפתרונות בין פרקי זמן קצרים יהיו דומים.

![[NUM1_004/NewtonIteration_Ani (1).gif|book|400]]
> דוגמה לשיטה איטרטיבית היא שיטת ניוטון-רפסון. מציאת השורש של הפונקציה $f(x)$ נעשית באמצעות סדרת קירובים תוך שימוש במשיק.


# שיטות איטרציה קבועות ושיטות הרפיה

>[!def] הגדרה: 
חלק מהאיטריצות שנעבור עליהם ניתנים לכתיבה בצורה של **איטריצה בנקודה קבועה**. עבור מערכת משוואות לינארית
$$A\bar{x}=\bar{b}$$
שנרשום *כמשוואה וקטורית*
$$\bar{f}(\bar{x})=\bar{b}-A\bar{x}=0$$
נחפש צורה שקולה של המשוואה:
$$\bar{g}(\bar{x})=\bar{x}$$
אנחנו מחפשים *נקודה קבועה* $\bar{x}^{*}$ כך שמתקיים:
$$\bar{x}^{*}=g(\bar{x}^{*})$$
נגדיר את האיטרציה:
$$\bar{x}_{k+1}=\bar{g}(\bar{x}_{k}),\, \quad k=0,1,\dots $$
כאשר נתחיל *מניחוש ראשוני* $\bar{x}_{0}$. אם הסדרה ${x}_{1},{x}_{2},\dots$ [[../CAL1/CAL1_003 גבולות של סדרות#גבול של סדרה|מתכנסת]], אז הגבול חייב להיות נקודה קבועה. הנקודה הקבועה הזאת היא הפתרון שלנו, כי הוא יקיים $\bar{f}(\bar{x}^{*})=0$, ובכך פותר לנו את המערכת משוואות.

אנחנו יכולים להגדיר המון פונקציות וקטוריות $\bar{g}$, למשל:
- $$\bar{g}(\bar{x})=\bar{x}-\bar{f}(\bar{x})$$
- $$\bar{g}(\bar{x})=\bar{x}+2f(\bar{x})$$

אבל לא $\bar{g}$ תתפקד באותה צורה, ולפעמים נעדיף אחת על פני האחרת. טענה זו תהיה יותר ברורה בהמשך.

## שיטות קבועות
עבור מערכת $A\bar{x}=\bar{b}$ נפרק את המטריצה לחיסור של שתי מטריצות $A=M-N$. לכן נוכל לרשום:
$$M\bar{x}=N\bar{x}+\bar{b}$$
נכפיל ב-$M^{-1}$ משמאל:
$$\begin{aligned}
\bar{x}&=M^{-1}N\bar{x}+M^{-1}\bar{b}
\end{aligned}$$
נוכל לרשום זאת בצורת איטרציה בנקודה קבועה:
$$\begin{aligned}
\bar{x}_{k+1}&=M^{-1}N\bar{x}_{k}+M^{-1}\bar{b} \\[1ex]
&=\bar{x}_{k}+M^{-1}(\bar{b}-A\bar{x}_{k})
\end{aligned}$$
כלומר, ה-$\bar{g}$ שלנו היא:
$$\bar{g}(\bar{x})=\bar{x}+M^{-1}(\bar{b}-A\bar{x})$$
שיטה כזו נקראת **שיטה קבועה** כי המטריצה שמכפילה את $\bar{x}$ לא תלויה באיטרציה ולכן קבועה. כעת נביט בבחירות שונות של $M$ (שלא בהכרח קבועות), בשיטות הרפיה:

## שיטות הרפיה
השיטות הבאות שנעסוק בהן נקראות **שיטות הרפיה** (relaxation methods)**. נביט במערכת המשוואות הלינארית $A\bar{x}=\bar{b}$ בצורה הבאה:
$$\begin{gather}
 & {a}_{11} {x}_{1} +{a}_{12} {x}_{2}  +\dots +a_{1n}x_{n}   \\
 & a_{21}{x}_{1} +{a}_{22} {x}_{2}  +\dots +a_{2n}x_{n}  \\
 &   \vdots  \\
 & a_{n 1}{x}_{1}+a_{n 2}{x}_{2}   +\dots +a_{nn}x_{n}
\end{gather}\begin{aligned}
&={b}_{1}  \\
&={b}_{2}  \\
&=\vdots  \\
&=b_{n}
\end{aligned}$$

נסמן את האיטרציה ה-$k$-ית ב-$\bar{x}_{k}$, כאשר את הרכיבים שלו נסמן ב-$x_{i}^{(k)}$. אז למשל
$$\bar{x}_{0}=({x}_{1} ^{(0)},{x}_{2} ^{(0)},\dots ,x_{n}^{(0)})^{T}$$
כאשר $\bar{x}_{0}$ נקרא גם *הניחוש הראשוני*. נביט קודם בשיטת יעקובי:

### #אלגוריתם: שיטת יעקובי
>[!def] הגדרה: 
 >
**בשיטת יעקובי (Jacobi)** שנקראת גםsimultaneous relaxtion, אנו בוחרים $M=D$, כאשר $D$ היא מטריצה אלכסונית המכילה רק את האלכסון הראשי של $A$:
$$\bar{x}_{k+1}=\bar{x}_{k}+D^{-1}(\bar{b}-A\bar{x}_{k})$$

כלומר, אנחנו מתחילים מניחוש ראשוני $\bar{x}_{0}$, וכל פעם מוסיפים לניחוש האחרון את השארית $\bar{r}=\bar{b}-A\bar{x}_{k}$ שמגדילים אותה פי $D^{-1}$. בכתיב אינדקסי:
$$\boxed {
x_{i}^{k+1}=\bar{x}_{i}^{(k)}+\dfrac{1}{a_{ii}}\left( b_{i}-\sum_{j=1}^{n} a_{ij}\bar{x}_{j}^{(k)} \right) \, \quad i=1,\dots ,n
 }$$
הרעיון שעומד מאחורי חישוב זה הוא שכל פעם $\bar{x}_{i}^{(k)}$ משתנה כדי לאפס עוד טיפה את השארית ה-$i$. קוראים לשיטות מסוג זה שיטות הרפיה כי אנחנו כל פעם "מרפים" את השארית לאפס.

בנוסף, בשיטה ספציפית זו, כל חישוב רכיב $x_{i}^{(k)}$ תלוי רק באיטרציות הקודמות של אותו רכיב $i$ (לעומת השיטה הבאה שנלמד). לכן ניתן לחשב את כל הרכיבים של איטרציה $k$ במקביל - מה שמוביל לשם simultaneous relaxtion.

>[!example] דוגמה: 
 >עבור מערכת המשוואות:
 >$$\begin{aligned}
&7{x}_{1} +3{x}_{2} +{x}_{3} =3 \\
 & -3{x}_{1} +10{x}_{2} +2{x}_{3} =4 \\
 & {x}_{1} +7{x}_{2} -15{x}_{3} =2
\end{aligned}$$
>אז:
>$$A=\begin{pmatrix}
7 & 3 & 1 \\
-3 & 10 & 2 \\
1 & 7 & -15
\end{pmatrix}\implies D=\begin{pmatrix}
7 & 0 & 0 \\
0 & 10 & 0 \\
0 & 0 & -15
\end{pmatrix},\, \quad \quad \bar{b}=\begin{pmatrix}
3 \\
4 \\
2
\end{pmatrix}$$
האיטרציה היעקובית ה-$k$ נתון ע"י:
>$$\begin{aligned}
 & {x}_{1} ^{(k+1)}=\dfrac{3-3{x}_{2} ^{(k)}-{x}_{3} ^{(k)}}{7} \\[1ex]
 & {x}_{2} ^{(k+1)}=\dfrac{4+3{x}_{1} ^{(k)}-2{x}_{3} ^{(k)}}{10} \\[1ex]
 & {x}_{3} ^{(k+1)}=\dfrac{2-{x}_{1} ^{(k)}-7{x}_{2} ^{(k)}}{-15}
\end{aligned}$$


### #אלגוריתם: שיטת גאוס-זיידל

>[!def] הגדרה: 
בשיטת **גאוס-זיידל** אנו בוחרים $M=E$, כאשר $E$ היא מטריצה משולשת תחתונה המכילה את האיברים המתאימים מ-$A$. נקבל שהאיטרציה ה-$k$-ית היא מהצורה:
$$\bar{x}_{k+1}=\bar{x}_{k}+E^{-1}(\bar{b}-A\bar{x}_{k})$$


מאחר ו-$E$ היא מטריצה משולשת תחתונה, כל רכיב שהרגע חישבנו באיטרציה $k$, משומש כדי לחשב רכיבים אחרים באותה האיטרציה. קל יותר לראות זאת בכתיב אינדקסי:
$$\boxed{x_{i}^{(k+1)}=x_{i}^{(k)}+\dfrac{1}{a_{ii}}\left( b_{i}-\sum_{j=1}^{i-1} a_{ij}x_{j}^{(k+1)}-\sum_{j=i}^{n} a_{ij}x_{j}^{(k)} \right) }$$

לכן, לעומת שיטת יעקובי, הסדר שבו מחושבים הרכיבים מאוד חשוב, וכבר אי אפשר לחשב את כולם במקביל. לכן, למרות ששיטת גאוס-זיידל מתכנסת יותר מהר משיטת יעקובי, קשה יותר לחשב אותו כי אי אפשר לחשב רכיב אחד בלי לחשב את הרכיב הקודם לו (באותה האיטרציה).

>[!example] דוגמה: 
 >אם נחזור לדוגמה הקודמת, מתקיים:
 >$$E=\begin{pmatrix}
7 & 0 & 0 \\
-3 & 10 & 0 \\
1 & 7 & -15
\end{pmatrix}$$
ולכן, לפי שיטת גאוס-זיידל:
>$$\begin{aligned}
&{x}_{1} ^{(k+1)}= \dfrac{3-3{x}_{2} ^{(k)}-{x}_{3} ^{(k)}}{7} \\[1ex]
&{x}_{2} ^{(k+1)}= \dfrac{4+3{x}_{1} ^{(k+1)}-2{x}_{3} ^{(k)}}{10} \\[1ex]
&{x}_{3} ^{(k+1)}= \dfrac{2-{x}_{1} ^{(k+1)}-7{x}_{2} ^{(k+1)}}{-15}
\end{aligned}$$

### #אלגוריתם: שיטת SOR
לכל אחד מהשיטות הקודמות אנחנו יכולים לבצע שינוי קטן באלגוריתם. שינוי זה תלוי בפרמטר $\omega>0$, והוא מציע להחליף בסוף כל איטרציה:
$$\omega \bar{x}_{x+1}+(1-\omega)\bar{x}_{k}\to \bar{x}_{k+1}$$
לשינוי זה על שיטת יעקובי אנו קוראים שיטת $\omega$-יעקובי, ובאותו אופן עבור שיטת $\omega$-גאוס-זיידל.

למעשה, לא חייבים לבצע את הפעולה הזאתי *רק* בסוף איטרציה, אפשר להכניס אותה בחישוב כל רכיב.

מסתבר שנגיע לפתרון מדויק הרבה יותר מהר כאשר נשתמש בשיטת $\omega$-גאוס-זיידל אם $\omega$ נמצא בטווח $1<\omega<2$. זה נקרא **שיטת SOR (successive over-relaxtion)**, והוא נתון ע"י:
$$\boxed {
{\bar{x}}_{i}^{(k+1)}=\bar{x}_{i}^{(k)}+\dfrac{\omega}{a_{ii}}\left[ \bar{b}_{i}-\sum_{j=1}^{i-1} a_{ij}\bar{x}_{j}^{(k+1)}-\sum_{j=i}^{n} a_{ij}\bar{x}_{j}^{(k)} \right]
 }$$
בכתיב מטריציוני, ה-$M$ שלנו הפך להיות מהצורה:
$$M=\dfrac{1-\omega}{\omega}D+E$$
ולכן:
$$\bar{x}_{k+1}=\bar{x}_{k}+\omega[(1-\omega)D+\omega E]^{-1}(\bar{b}-A\bar{x}_{k})$$

>[!example] דוגמה: 
 >שוב, נשתמש באותה דוגמה, ונקבל כי לפי שיטת SOR:
 >$$\begin{aligned}
 & {x}_{1} ^{(k+1)}=(1-\omega){x}_{1} ^{(k)}+\omega \dfrac{3-3{x}_{2} ^{(k)}-{x}_{3} ^{(k)}}{7} \\[1ex]
 & {x}_{2} ^{(k+1)}=(1-\omega){x}_{2} ^{(k)}+\omega \dfrac{4+3{x}_{1} ^{(k+1)}-2{x}_{3} ^{(k)}}{10} \\[1ex]
 & {x}_{3} ^{(k+1)}=(1-\omega){x}_{3} ^{(k)}+\omega \dfrac{2-{x}_{1} ^{(k+1)}-7{x}_{2} ^{(k+1)}}{-15}
\end{aligned}$$

# התכנסות שיטות איטרטיביות למערכות לינאריות

כדי שנוכל לדבר על התכנסות שיטות איטרטיביות למערכות לינאריות, נרצה להמיר את השיטות להצגן המטריציונית. נזכור כי בכל איטרציה השארית (שאנו יודעים לחשב אותה) היא:
$$\bar{r}_{k}=\bar{b}-A\bar{x}_{k}$$
והשגיאה (שאנו לא יודעים לחשב אותה):
$$\bar{e}=\bar{x}-\bar{x}_{k}=A^{-1}\bar{r}_{k}$$
ובכל זאת, נרצה לדעת אם השיטה מתכנסת. כלומר, ש-$\bar{e}_{k}\to 0$ כאשר $k\to \infty$.

## מטריצת האיטרציה
ב[[#שיטות קבועות]] רשמנו:
$$\begin{gather} 
\bar{x}_{k}=M^{-1}\bar{b}+(I-M^{-1}A)\bar{x}_{k-1}\\
\bar{x}=M^{-1}\bar{b}+(I-M^{-1}A)\bar{x}
\end{gather}$$
נחסר בין המשוואות:
$$\bar{x}-\bar{x}_{k}=(I-M^{-1}A)(\bar{x}-\bar{x}_{k-1})$$
נגדיר $G=I-M^{-1}A$, ונקבל:
$$\begin{aligned}
\bar{e}_{k}&=G\bar{e}_{k-1} \\
&=G(G\bar{e}_{k-2})=\dots  \\
&=G^{k}\bar{e}_{0}
\end{aligned}$$
למטריצה $G$ אנו קוראים **מטריצת האיטרציה**. מאחר ו-$\bar{e}_{0}$ היא השגיאה הראשונית והיא מספר קבוע, אנו נקבל התכנסות $\bar{e}_{k}\to 0$ אם"ם $G^{k}\to 0$.

זהו המקרה אם למשל:
$$\| G\|_{}<1 $$
כי:
$$\| \bar{e}_{k}\|_{}=\| G\cdot G\cdots G\bar{e}_{0}\|_{}\leq \| G\|_{}\| G\|_{}\cdots \| G\|_{}\| \bar{e}_{0}\|_{}=\| G\|_{}^{k}\| \bar{e}_{0}\|_{}$$

כלומר, קיבלנו ש- $\| G\|_{}<1$ הוא תנאי מספיק להתכנסות השיטה.
למעשה, ניתן לומר שההתכנסות תלויה ברדיוס הספקטרלי של $G$:
## התכנסות שיטה איטרטיבית
>[!theorem] משפט: 
 >עבור המערכת משוואות לינאריות $A\bar{x}=\bar{b}$, והשיטה האיטרטיבית:
 >$$\bar{x}_{k+1}=\bar{x}_{k}+M^{-1}\bar{r}_{k},\, \quad k=0,1,\dots $$
 >נגדיר את מטריצת האיטרציה $G=I-M^{-1}A$. אזי, השיטה מתכנסת אם"ם הרדיוס הספקטרלי של מטריצת האיטריצה מקיימת:
 >$$\rho (G)<1$$
 >ככל ש-$\rho(G)$ יותר קטן, ההתכנסות יותר מהירה.
 
נרצה לדעת כמה איטרציות אנו צריכים לבצע כדי להקטין את הנורמה של השגיאה בלמשל, פי $10$? כלומר נרצה לדעת עבור איזה $k$ נקבל:
$$0.1\| \bar{e}_{0}\|_{}\approx \| \bar{e}_{k}\|_{}\approx \rho(G)^{k}\| \bar{e}_{0}\|_{}  $$
נוציא $\log$, כך שנמצא שנדרשים
$$k\approx -\dfrac{1}{\log_{10}\rho(G)}$$
איטרציות כדי להקטין את השגיאה ב-$10$. לכן, נגדיר את **קצב ההתכנסות**:
$$\text{rate}=-\log_{10}\rho(G)$$
לפעמים מגדירים את קצב ההתכנסות גם כ:
$$\text{rate}=-\ln \rho(G)$$
ולפעמים, אומרים ש-$\rho(G)$ עצמו הוא קצב ההתכנסות, או אפילו $\dfrac{1}{\rho(G)}$. תלוי שאלה.
